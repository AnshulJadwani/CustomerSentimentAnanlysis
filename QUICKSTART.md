# ğŸš€ Quick Start Guide

## Get Started in 5 Minutes!

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Download NLTK Data

```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('punkt_tab')"
```

### 3ï¸âƒ£ Choose Your Path

#### ğŸ“ **Learning Path** - Jupyter Notebook

Best for understanding the complete workflow:

```bash
jupyter notebook
# Then open notebooks/sentiment_analysis.ipynb
```

**What you'll learn:**
- Data exploration and preprocessing
- Feature engineering with TF-IDF
- Training multiple ML models
- Model evaluation and comparison
- Visualization techniques

---

#### âš¡ **Quick Training** - Command Line

Train models directly from terminal:

```bash
python main.py train --data data/clean_review.csv
```

This will:
- Load and preprocess data
- Train all models (LR, NB, SVM)
- Save models to `models/` directory
- Display performance metrics

---

#### ğŸŒ **Interactive Demo** - Web App

Try the live web interface:

```bash
streamlit run app/app.py
```

Then visit: http://localhost:8501

**Features:**
- Real-time sentiment prediction
- Confidence scores
- Model comparison
- Sample reviews

---

### 4ï¸âƒ£ Make Predictions

After training, predict sentiment for any review:

```bash
python main.py predict --text "This phone is amazing! Great camera quality."
```

---

## ğŸ“š Need More Help?

- **Full Documentation**: See [README.md](README.md)
- **Project Details**: Check [Instructions.md](Instructions.md)
- **Code Issues**: Check preprocessing in `utils/preprocessing.py`

---

## ğŸ¯ Expected Results

After running the notebook or training:

âœ… 3 trained models saved
âœ… TF-IDF vectorizer saved
âœ… Performance metrics (85-93% accuracy expected)
âœ… Model comparison visualizations
âœ… Ready-to-use prediction system

---

## ğŸ’¡ Tips

1. **First time?** â†’ Start with the Jupyter notebook
2. **Production use?** â†’ Use `main.py` for training
3. **Demo/Presentation?** â†’ Use Streamlit app
4. **Custom data?** â†’ Replace `data/clean_review.csv`

---

## âš ï¸ Common Issues

**Problem**: NLTK data not found
```bash
# Solution:
python -c "import nltk; nltk.download('all')"
```

**Problem**: Module not found error
```bash
# Solution: Install requirements again
pip install -r requirements.txt --upgrade
```

**Problem**: Models not found in Streamlit
```bash
# Solution: Train models first
python main.py train --data data/clean_review.csv
```

---

Happy Analyzing! ğŸ‰
